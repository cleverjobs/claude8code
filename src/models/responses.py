"""Response models matching Anthropic's Messages API schema.

These models ensure compatibility with clients expecting
the official API response format.
"""

from __future__ import annotations

from typing import Any, Literal

from pydantic import BaseModel

from .requests import Citation


class CacheCreationUsage(BaseModel):
    """Detailed cache creation usage by TTL."""
    ephemeral_5m_input_tokens: int = 0
    ephemeral_1h_input_tokens: int = 0


class ServerToolUsage(BaseModel):
    """Server-side tool usage statistics."""
    web_search_requests: int = 0


class Usage(BaseModel):
    """Token usage information."""
    input_tokens: int
    output_tokens: int
    cache_creation_input_tokens: int | None = None
    cache_read_input_tokens: int | None = None
    cache_creation: CacheCreationUsage | None = None
    server_tool_use: ServerToolUsage | None = None
    service_tier: Literal["standard", "priority", "batch"] | None = None


class TextBlock(BaseModel):
    """Text block in response content."""
    type: Literal["text"] = "text"
    text: str
    citations: list[Citation] | None = None


class ThinkingBlock(BaseModel):
    """Thinking block in response content (extended thinking / ultrathink).

    Contains Claude's reasoning process when extended thinking is enabled.
    The signature field is used for verification that the thinking content
    was genuinely generated by Claude.
    """
    type: Literal["thinking"] = "thinking"
    thinking: str
    signature: str | None = None


class RedactedThinkingBlock(BaseModel):
    """Redacted thinking block when thinking content is hidden."""
    type: Literal["redacted_thinking"] = "redacted_thinking"
    data: str


class ToolUseResponseBlock(BaseModel):
    """Tool use block in response."""
    type: Literal["tool_use"] = "tool_use"
    id: str
    name: str
    input: dict[str, Any]


ResponseContentBlock = TextBlock | ThinkingBlock | RedactedThinkingBlock | ToolUseResponseBlock


StopReason = Literal[
    "end_turn",
    "max_tokens",
    "stop_sequence",
    "tool_use",
    "pause_turn",
    "refusal",
    "model_context_window_exceeded",
]


class MessagesResponse(BaseModel):
    """Response body for POST /v1/messages - matches Anthropic's schema."""
    id: str
    type: Literal["message"] = "message"
    role: Literal["assistant"] = "assistant"
    content: list[ResponseContentBlock]
    model: str
    stop_reason: StopReason | None = None
    stop_sequence: str | None = None
    usage: Usage


class ModelInfo(BaseModel):
    """Information about a single model - matches official Anthropic API format."""
    id: str
    type: Literal["model"] = "model"
    display_name: str
    created_at: str  # RFC 3339 datetime string


class ModelsListResponse(BaseModel):
    """Response for GET /v1/models - matches official Anthropic API format."""
    data: list[ModelInfo]
    first_id: str | None = None
    last_id: str | None = None
    has_more: bool = False


class CountTokensResponse(BaseModel):
    """Response for POST /v1/messages/count_tokens - matches Anthropic's schema."""
    input_tokens: int
